{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Name: Burn Pizza vs Good Pizza Classification Using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A famous 30 year old pizza brand which has outlets in more than 90 countries started home\n",
    "delivery services a couple of years ago and the business has grown much faster than expected.\n",
    "However, outlet vendors are very much disappointed with few customers for their cheating\n",
    "activities. This is because vendors, shockingly, came to know that few customers after receiving the\n",
    "delivery are raising tickets for refund in the name of burnt pizzas. Even though customers received\n",
    "a good pizza but still few customers are trying to cheat vendors. To overcome this issue, Franchise\n",
    "has come up with an idea to integrate a pizza detection model in their application where customers\n",
    "can upload images for the burnt pizzas delivered. For example, if I have received a burnt pizza then\n",
    "I can upload a couple of images of the pizza to the application and it will classify the pizza as burnt\n",
    "or good in order to process my refund ticket.\n",
    "\n",
    "**Goal:** You are hired as Deep Learning Engineer by a famous pizza franchise. You are asked to build\n",
    "a model where it accepts the images of pizza and detects as burnt pizza or good pizza.\n",
    "\n",
    "**Constraints:** You should be using only ANN and shouldnâ€™t be using CNN or any other rule based\n",
    "model to generate results.\n",
    "\n",
    "**Data Description:** Data is in the form of images collected from multiple sources of the internet.\n",
    "    \n",
    "**Provided Files:**\n",
    "**Train set:** Train set is divided into burnt pizza and good pizza categories. While training the\n",
    "model you can label images of good pizza as 1 and burnt pizza as 0.\n",
    "\n",
    "**Test:** Test set contains mixed images of both burnt pizzas and good pizzas.\n",
    "    \n",
    "**Instructions:**\n",
    "1. Train set should be used to feed the model.\n",
    "2. Test set should be used to predict labels for test data.\n",
    "\n",
    "**Evaluation Criteria:** The evaluation metric for this problem statement is the Accuracy score\n",
    "where each image label is matched with the actual image label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "    \n",
    "1. Importing (or installing) Tenosrflow, Keras and other packages on your system\n",
    "2. Loading data from disk\n",
    "3. Creating your training and testing splits\n",
    "4. Data Preprocessing \n",
    "5. Defining your tensorflow ANN model architecture\n",
    "6. Compiling your tensorflow ANN model\n",
    "7. Training your model on your training data\n",
    "8. Evaluating your model on your test data\n",
    "9. Generate Plots for accuracy and validation loss\n",
    "10. Saving The train model\n",
    "11. Making predictions using your trained tensorflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing all the packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import warnings\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading data from disk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e43b1985174322930a33f9ea79a618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/709 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 109.8 seconds\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "time1=time.time()    # to measure time taken\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "classes=[\"Good_pizza\",\"Burnt_pizza\"]\n",
    "\n",
    "#grab the image path and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(\"train\")))\n",
    "random.seed(SEED)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "#progress bar\n",
    "\n",
    "with tqdm(total=len(imagePaths)) as pbar:\n",
    "    \n",
    "    #loop over the input images\n",
    "    for imagePath in imagePaths:\n",
    "        #load the image, resize the image to be 32*32 pixel (ignoring aspect ratio),\n",
    "        #flatten the 32*32*3 =3072 pixel image into a list, and store image in data list\n",
    "        image =cv2.imread(imagePath)\n",
    "        image = cv2.resize(image,(32,32)).flatten()\n",
    "        data.append(image)\n",
    "        \n",
    "        #Extract the class label from the image path and update the label list\n",
    "        label=imagePath.split(os.path.sep)[-2]\n",
    "        \n",
    "        label = 1 if label == \"Burnt_pizza\" else 0\n",
    "        labels.append(label)\n",
    "        \n",
    "        #update the progressbar\n",
    "        pbar.update(1)\n",
    "\n",
    "#scale the raw pixel intensities to the range [0,1]\n",
    "data=np.array(data,dtype=\"float\")/255.0\n",
    "labels=np.array(labels)\n",
    "\n",
    "print(\"Time Taken: {:.1f} seconds\".format(time.time()-time1)) # to measure the time taken\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images:  709\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Images: \",len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image: [0.3254902  0.25098039 0.22352941 ... 0.33333333 0.30980392 0.29019608]\n",
      "no of features/pixels values: 3072\n",
      "label:Good_pizza\n"
     ]
    }
   ],
   "source": [
    "#Sample data for first image\n",
    "print(\"Sample image: {}\".format(data[0]))\n",
    "print(\"no of features/pixels values: {}\".format(len(data[0]))) #32*32*3=3072\n",
    "print(\"label:{}\".format(classes[labels[0]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Training and Testing Splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partition the data into 80% training and 20 % validation\n",
    "(trainX,testX,trainY,testY)= train_test_split(data,labels,test_size=0.2,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(567, 3072)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(567,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142, 3072)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86666667, 0.85882353, 0.81960784, ..., 0.23921569, 0.2627451 ,\n",
       "        0.80784314],\n",
       "       [0.09019608, 0.49803922, 0.85098039, ..., 0.2745098 , 0.63921569,\n",
       "        0.88627451],\n",
       "       [0.99607843, 0.99607843, 0.99607843, ..., 0.99607843, 0.99607843,\n",
       "        0.99607843],\n",
       "       ...,\n",
       "       [0.07058824, 0.16078431, 0.37647059, ..., 0.86666667, 0.89411765,\n",
       "        0.95294118],\n",
       "       [0.06666667, 0.09019608, 0.2       , ..., 0.17254902, 0.19215686,\n",
       "        0.2627451 ],\n",
       "       [0.23921569, 0.25098039, 0.25098039, ..., 0.7254902 , 0.72156863,\n",
       "        0.71764706]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
